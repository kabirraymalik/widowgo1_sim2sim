seed: 42
device: cuda:0
num_steps_per_env: 24
max_iterations: 15000
empirical_normalization: false
obs_groups: {}
clip_actions: null
save_interval: 1000
experiment_name: widowgo1_flat
run_name: ''
logger: wandb
neptune_project: isaaclab
wandb_project: isaaclab
resume: false
load_run: .*
load_checkpoint: model_.*.pt
class_name: OnPolicyRunner
policy:
  class_name: ActorCritic
  init_noise_std: 1.0
  noise_std_type: scalar
  actor_obs_normalization: {}
  critic_obs_normalization: {}
  actor_hidden_dims:
  - 256
  critic_hidden_dims:
  - 256
  activation: elu
  activation_out: elu
  leg_control_head_hidden_dims:
  - 256
  - 128
  arm_control_head_hidden_dims:
  - 256
  - 128
  critic_leg_control_head_hidden_dims:
  - 256
  - 128
  - 64
  critic_arm_control_head_hidden_dims:
  - 256
  - 128
  - 64
  priv_encoder_dims:
  - 32
  - 18
  num_leg_actions: 12
  num_arm_actions: 6
algorithm:
  class_name: PPO
  num_learning_epochs: 5
  num_mini_batches: 4
  learning_rate: 0.001
  schedule: adaptive
  gamma: 0.99
  lam: 0.95
  entropy_coef: 0.005
  desired_kl: 0.01
  max_grad_norm: 1.0
  value_loss_coef: 1.0
  use_clipped_value_loss: true
  clip_param: 0.2
  normalize_advantage_per_mini_batch: false
  rnd_cfg: null
  symmetry_cfg: null
  dagger_update_freq: 20
  priv_reg_coef_schedual:
  - 0
  - 0.1
  - 1500
  - 5000
  mixing_schedule:
  - 1.0
  - 0
  - 4000
  eps: 1.0e-05
